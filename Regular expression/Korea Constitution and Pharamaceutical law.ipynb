{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install PyPDF2\n",
        "%pip install -U PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSot77m2aqEv",
        "outputId": "f338c5b9-4162-441b-cb9c-d3b93ee060f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "pwbJkRRRMHXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, pathlib, os, fitz\n",
        "from pathlib import Path\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "5zNdLoC9MIUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting constitution law"
      ],
      "metadata": {
        "id": "5nBMiCh1L6Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the PDF file\n",
        "pdf_path = \"/content/CONSTITUTION OF THE REPUBLIC OF KOREA.pdf\"\n",
        "\n",
        "# Read the PDF\n",
        "reader = PdfReader(pdf_path)\n",
        "full_text = \"\"\n",
        "\n",
        "# Collect text from all pages (remove page numbers and word breaks)\n",
        "for page in reader.pages:\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        # Remove page numbers like \"Page 1\", \"Page 2\", etc.\n",
        "        text = re.sub(r'\\bPage\\s*\\d+\\b', '', text)  # \\s* matches any number of spaces (0 or more)\n",
        "        # Remove lines that consist only of numbers (likely page headers/footers)\n",
        "        text = re.sub(r'^\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
        "        # Remove line breaks within paragraphs, while preserving double line breaks (new paragraphs)\n",
        "        text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
        "        full_text += text + \"\\n\"\n",
        "\n",
        "# Split text by \"Article\" headers (e.g., Article 1, Article 2, ...)\n",
        "# The (?=...) is a lookahead to keep the \"Article N\" line at the start of each chunk\n",
        "article_chunks = re.split(r'(?=Article \\d+)', full_text)\n",
        "\n",
        "# Path to save the result\n",
        "output_path = \"/content/result.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for chunk in article_chunks:\n",
        "        chunk = chunk.strip()\n",
        "        if chunk:\n",
        "            f.write(chunk + \"\\n\\n---\\n\\n\")"
      ],
      "metadata": {
        "id": "4pYLB6sZS9el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Pharmaceutical laws"
      ],
      "metadata": {
        "id": "Y7bBbsyNMCdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────\n",
        "# 1. Just modify the path to your PDF\n",
        "# ────────────────────────────────\n",
        "PDF_PATH = \"/content/PHARMACEUTICAL AFFAIRS ACT.pdf\"   # ★ Set to your desired location\n",
        "\n",
        "# ────────────────────────────────\n",
        "# 2. Output will be saved in the same folder as the PDF\n",
        "# ────────────────────────────────\n",
        "BASE_DIR   = pathlib.Path(PDF_PATH).expanduser().resolve().parent\n",
        "# .expanduser(): expands ~ to full home directory path\n",
        "# .resolve(): resolves relative paths and symbolic links to absolute paths\n",
        "# .parent: gets the parent directory of the file (i.e., the folder containing the PDF)\n",
        "\n",
        "CLEAN_TXT  = BASE_DIR / \"pharma_cleaned.txt\"\n",
        "BYCHAP_TXT = BASE_DIR / \"pharma_by_chapter.txt\"\n",
        "\n",
        "# ────────────────────────────────\n",
        "# 3. Common text-cleaning function\n",
        "def clean_text(txt: str) -> str:\n",
        "    # txt: str → str means this function takes and returns a string (type hints)\n",
        "\n",
        "    # 1) Patterns to remove in bulk\n",
        "    # .*? means match any character 0 or more times, non-greedy (as short as possible)\n",
        "    # \\] and \\. are escaped to match literal characters\n",
        "    patterns = [\n",
        "        r'\\bPage\\s*\\d+\\b',\n",
        "        r'법제처.*?국가법령정보센터',\n",
        "        r'www\\.law\\.go\\.kr',\n",
        "        r'\\d{2,4}-\\d{3,4}-\\d{4}',  # \\d{2,4}: 2 to 4 digit numbers\n",
        "        r'PHARMACEUTICAL AFFAIRS ACT',\n",
        "        r'\\[Enforcement Date.*?\\]',\n",
        "        r'\\[Act No\\..*?\\]',\n",
        "        r'\\s*터\\s*「\\s*」\\s*',     # The pattern '터 「」' plus any whitespace or line breaks\n",
        "    ]\n",
        "\n",
        "    # Use re.sub to replace all matched patterns with a space (case-insensitive)\n",
        "    txt = re.sub(\"|\".join(patterns), \" \", txt, flags=re.I)\n",
        "    # Example: re.sub(\"abc|123|def\", \" \", txt)\n",
        "\n",
        "    # 2) Remove isolated Korean characters (e.g., leftover '터')\n",
        "    txt = re.sub(r'[가-힣]', '', txt)\n",
        "\n",
        "    # 3) Merge line breaks that appear within lines (not paragraph breaks)\n",
        "    txt = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', txt)\n",
        "\n",
        "    # 4) Remove any remaining empty brackets 「」\n",
        "    txt = re.sub(r'\\s*「\\s*」\\s*', ' ', txt)\n",
        "\n",
        "    # 5) Remove any header text before the first CHAPTER\n",
        "    m = re.search(r'CHAPTER\\s+[IVXLC]+\\b', txt)  # \\s+ means one or more whitespace characters\n",
        "    if m:\n",
        "        txt = txt[m.start():]  # Trim text before CHAPTER\n",
        "\n",
        "    # 6) Convert 3 or more newlines into exactly 2\n",
        "    txt = re.sub(r'\\n{3,}', '\\n\\n', txt)\n",
        "\n",
        "    # 7) Collapse multiple spaces into one\n",
        "    txt = re.sub(r' {2,}', ' ', txt)  # ' {2,}' = 2 or more consecutive spaces\n",
        "\n",
        "    return txt.strip()  # Remove leading/trailing whitespace\n",
        "\n",
        "# ────────────────────────────────\n",
        "# 4. Extract text → clean it\n",
        "# ────────────────────────────────\n",
        "if not CLEAN_TXT.exists():\n",
        "    doc = fitz.open(PDF_PATH)  # Open PDF with PyMuPDF; pages accessible as doc[n]\n",
        "    raw_text = \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
        "    # Joins all page texts into one string, separated by line breaks\n",
        "    CLEAN_TXT.write_text(clean_text(raw_text), encoding=\"utf-8\")\n",
        "\n",
        "cleaned = CLEAN_TXT.read_text(encoding=\"utf-8\")\n",
        "\n",
        "# ────────────────────────────────\n",
        "# 5. Save by CHAPTER block\n",
        "# ────────────────────────────────\n",
        "with BYCHAP_TXT.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for block in re.split(r'(?=CHAPTER\\s+[IVXLC]+\\b)', cleaned):\n",
        "        # (?=...) is a lookahead, so CHAPTER stays at the start of each block\n",
        "        block = block.strip()\n",
        "        if not block:\n",
        "            continue  # Skip if block is empty\n",
        "        m = re.match(r'CHAPTER\\s+[IVXLC]+\\b[^\\n]*', block)\n",
        "        # Match full CHAPTER title on the first line (until newline)\n",
        "        if not m:\n",
        "            continue\n",
        "        chap_title = m.group()  # Extract matched CHAPTER title\n",
        "        body = block[m.end():].lstrip()  # Get the rest of the block, remove left whitespace\n",
        "        f.write(chap_title + \"\\n\\n\")\n",
        "        f.write(body + \"\\n\\n\")\n",
        "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "# Example structure:\n",
        "# blocks = [\n",
        "#   '',  # Empty string before CHAPTER I\n",
        "#   'CHAPTER I GENERAL PROVISIONS\\nArticle 1 (Purpose)\\n...',\n",
        "#   'CHAPTER II APPROVAL\\nArticle 5 (Approval of drugs)\\n...'\n",
        "# ]\n",
        "\n",
        "print(f\"Complete \\n- cleaned → {CLEAN_TXT}\\n- by-chapter → {BYCHAP_TXT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok-lCJYZRLrq",
        "outputId": "98ba82f9-3b4b-447d-a59d-ab49549239f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete \n",
            "- cleaned → /content/pharma_cleaned.txt\n",
            "- by-chapter → /content/pharma_by_chapter.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Lookahead (?=...): There must be ... after the current position\n",
        "\n",
        "Negative Lookahead (?!...): There must not be ... after the current position\n",
        "\n",
        "Positive Lookbehind (?<=...): There must be ... before the current position\n",
        "\n",
        "Negative Lookbehind (?<!...): There must not be ... before the current position\n",
        "\n"
      ],
      "metadata": {
        "id": "qyHtvda0S9B7"
      }
    }
  ]
}